Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Adams2019,
abstract = {This paper describes LFRic: the new weather and climate modelling system being developed by the UK Met Office to replace the existing Unified Model in preparation for exascale computing in the 2020s. LFRic uses the GungHo dynamical core and runs on a semi-structured cubed-sphere mesh. The design of the supporting infrastructure follows object-oriented principles to facilitate modularity and the use of external libraries where possible. In particular, a â€˜separation of concerns' between the science code and parallel code is imposed to promote performance portability. An application called PSyclone, developed at the STFC Hartree centre, can generate the parallel code enabling deployment of a single source science code onto different machine architectures. This paper provides an overview of the scientific requirement, the design of the software infrastructure, and examples of PSyclone usage. Preliminary performance results show strong scaling and an indication that hybrid MPI/OpenMP performs better than pure MPI.},
archivePrefix = {arXiv},
arxivId = {1809.07267},
author = {Adams, S. V. and Ford, R. W. and Hambley, M. and Hobson, J. M. and Kav{\v{c}}i{\v{c}}, I. and Maynard, C. M. and Melvin, T. and M{\"{u}}ller, E. H. and Mullerworth, S. and Porter, A. R. and Rezny, M. and Shipway, B. J. and Wong, R.},
doi = {10.1016/j.jpdc.2019.02.007},
eprint = {1809.07267},
file = {::},
issn = {07437315},
journal = {J. Parallel Distrib. Comput.},
keywords = {Domain specific language,Exascale,Numerical weather prediction,Separation of concerns},
month = {oct},
pages = {383--396},
publisher = {Academic Press Inc.},
title = {{LFRic: Meeting the challenges of scalability and performance portability in Weather and Climate models}},
volume = {132},
year = {2019}
}
@inproceedings{Lee2019,
abstract = {Although data partitioning is required to enable parallelism on distributed memory systems, data partitions are not first class objects in most distributed programming models. As a result, automatic parallelizers and application writers encode a particular partitioning strategy in the parallelized program, leading to a program not easily configured or composed with other parallel programs. We present a constraint-based approach to automatic data partitioning. By introducing abstractions for first-class data partitions, we express a space of correct partitioning strategies. Candidate partitions are characterized by partitioning constraints, which can be automatically inferred from data accesses in parallelizable loops. Constraints can be satisfied by synthesized partitioning code or user-provided partitions. We demonstrate that programs auto-parallelized in our approach are easily composed with manually parallelized parts and have scalability comparable to hand-optimized counterparts.},
author = {Lee, Wonchan and Papadakis, Manolis and Slaughter, Elliott and Aiken, Alex},
booktitle = {Int. Conf. High Perform. Comput. Networking, Storage Anal. SC},
doi = {10.1145/3295500.3356199},
file = {::},
isbn = {9781450362290},
issn = {21674337},
keywords = {Auto-parallelization,Data partitioning,First-class data partitions,Partitioning constraints},
month = {nov},
publisher = {IEEE Computer Society},
title = {{A constraint-based approach to automatic data partitioning for distributed memory execution}},
year = {2019}
}
@misc{Shalf2020,
abstract = {Moore's Law is a techno-economic model that has enabled the information technology industry to double the performance and functionality of digital electronics roughly every 2 years within a fixed cost, power and area. Advances in silicon lithography have enabled this exponential miniaturization of electronics, but, as transistors reach atomic scale and fabrication costs continue to rise, the classical technological driver that has underpinned Moore's Law for 50 years is failing and is anticipated to flatten by 2025. This article provides an updated view of what a post-exascale system will look like and the challenges ahead, based on our most recent understanding of technology roadmaps. It also discusses the tapering of historical improvements, and how it affects options available to continue scaling of successors to the first exascale machine. Lastly, this article covers the many different opportunities and strategies available to continue computing performance improvements in the absence of historical technology drivers. This article is part of a discussion meeting issue 'Numerical algorithms for high-performance computational science'.},
author = {Shalf, John},
booktitle = {Philos. Trans. R. Soc. A Math. Phys. Eng. Sci.},
doi = {10.1098/rsta.2019.0061},
file = {::},
issn = {1364503X},
keywords = {Computing,High-performance computing,Lithography,Microelectronics,Moore's Law,Post-CMOS},
month = {mar},
number = {2166},
pmid = {31955683},
publisher = {Royal Society Publishing},
title = {{The future of computing beyond Moore's Law}},
volume = {378},
year = {2020}
}
@article{Zhang2020,
abstract = {With semiconductor technology gradually approaching its physical and thermal limits, recent supercomputers have adopted major architectural changes to continue increasing the performance through more power-efficient heterogeneous many-core systems. Examples include Sunway TaihuLight that has four management processing elements (MPEs) and 256 computing processing elements (CPEs) inside one processor and Summit that has two central processing units (CPUs) and six graphics processing units (GPUs) inside one node. Meanwhile, current high-resolution Earth system models that desperately require more computing power generally consist of millions of lines of legacy code developed for traditional homogeneous multicore processors and cannot automatically benefit from the advancement of supercomputer hardware. As a result, refactoring and optimizing the legacy models for new architectures become key challenges along the road of taking advantage of greener and faster supercomputers, providing better support for the global climate research community and contributing to the long-lasting societal task of addressing long-term climate change. This article reports the efforts of a large group in the International Laboratory for High-Resolution Earth System Prediction (iHESP) that was established by the cooperation of Qingdao Pilot National Laboratory for Marine Science and Technology (QNLM), Texas A{\&}M University (TAMU), and the National Center for Atmospheric Research (NCAR), with the goal of enabling highly efficient simulations of the high-resolution (25 km atmosphere and 10 km ocean) Community Earth System Model (CESM-HR) on Sunway Taihu- Light. The refactoring and optimizing efforts have improved the simulation speed of CESM-HR from 1 SYPD (simulation years per day) to 3.4 SYPD (with output disabled) and supported several hundred years of pre-industrial control simulations. With further strategies on deeper refactoring and optimizing for remaining computing hotspots, as well as redesigning architecture-oriented algorithms, we expect an equivalent or even better efficiency to be gained on the new platform than traditional homogeneous CPU platforms. The refactoring and optimizing processes detailed in this paper on the Sunway system should have implications for similar efforts on other heterogeneous many-core systems such as GPU-based high-performance computing (HPC) systems.},
author = {Zhang, Shaoqing and Fu, Haohuan and Wu, Lixin and Li, Yuxuan and Wang, Hong and Zeng, Yunhui and Duan, Xiaohui and Wan, Wubing and Wang, Li and Zhuang, Yuan and Meng, Hongsong and Xu, Kai and Xu, Ping and Gan, Lin and Liu, Zhao and Wu, Sihai and Chen, Yuhu and Yu, Haining and Shi, Shupeng and Wang, Lanning and Xu, Shiming and Xue, Wei and Liu, Weiguo and Guo, Qiang and Zhang, Jie and Zhu, Guanghui and Tu, Yang and Edwards, Jim and Baker, Allison and Yong, Jianlin and Yuan, Man and Yu, Yangyang and Zhang, Qiuying and Liu, Zedong and Li, Mingkui and Jia, Dongning and Yang, Guangwen and Wei, Zhiqiang and Pan, Jingshan and Chang, Ping and Danabasoglu, Gokhan and Yeager, Stephen and Rosenbloom, Nan and Guo, Ying},
doi = {10.5194/gmd-13-4809-2020},
file = {::},
issn = {19919603},
journal = {Geosci. Model Dev.},
month = {oct},
number = {10},
pages = {4809--4829},
publisher = {Copernicus GmbH},
title = {{Optimizing high-resolution Community Earth System Model on a heterogeneous many-core supercomputing platform}},
volume = {13},
year = {2020}
}
@article{Theis2017,
abstract = {The insights contained in Gordon Moore's now famous 1965 and 1975 papers have broadly guided the development of semiconductor electronics for over 50 years. However, the field-effect transistor is approaching some physical limits to further miniaturization, and the associated rising costs and reduced return on investment appear to be slowing the pace of development. Far from signaling an end to progress, this gradual 'end of Moore's law' will open a new era in information technology as the focus of research and development shifts from miniaturization of long-established technologies to the coordinated introduction of new devices, new integration technologies, and new architectures for computing.},
author = {Theis, Thomas N and {Philip Wong}, H. S.},
doi = {10.1109/MCSE.2017.29},
file = {::},
issn = {15219615},
journal = {Comput. Sci. Eng.},
keywords = {algorithms implemented in hardware,emerging technologies,introductory and survey,memory technologies,neural nets,scientific computing},
number = {2},
pages = {41--50},
title = {{The End of Moore's Law: A New Beginning for Information Technology}},
url = {https://purl.stanford.edu/gc095kp2609.},
volume = {19},
year = {2017}
}
@inproceedings{Fu2017,
abstract = {The Community Atmosphere Model (CAM) is ported, redesigned, and scaled to the full system of the Sunway TaihuLight, and provides peta-scale climate modeling performance. We refactored and optimized the complete code using OpenACC directives at the frst stage. A more aggressive and fner-grained redesign is then applied on the CAM, to achieve fner memory control and usage, more efficient vectorization and compute and communication overlapping. We further improve the CAM performance of a 260-core Sunway processor to the range of 28 to 184 Intel CPU cores, and achieve a sustainable double-precision performance of 3.3 PFlops for a 750 m global simulation when using 10,075,000 cores. CAM on Sunway achieves the simulation speed of 3.4 and 21.5 simulation-year-perday (SYPD) for global 25-km and 100-km resolution respectively; and enables us to perform, to our knowledge, the frst simulation of the complete lifecycle of hurricane Katrina, and achieve close-to-observation simulation results for both track and intensity.},
author = {Fu, Haohuan and Liao, Junfeng and Ding, Nan and Duan, Xiaohui and Gan, Lin and Liang, Yishuang and Wang, Xinliang and Yang, Jinzhe and Zheng, Yan and Liu, Weiguo and Wang, Lanning and Yang, Guangwen},
booktitle = {Proc. Int. Conf. High Perform. Comput. Networking, Storage Anal. SC 2017},
doi = {10.1145/3126908.3126909},
file = {::},
isbn = {9781450351140},
month = {nov},
publisher = {Association for Computing Machinery, Inc},
title = {{Redesigning CAM-SE for peta-scale climate modeling performance and ultra-high resolution on sunway taihulight}},
year = {2017}
}
@inproceedings{Bertagna2020,
abstract = {We present an effort to port the nonhydrostatic atmosphere dynamical core of the Energy Exascale Earth System Model (E3SM) to efficiently run on a variety of architectures, including conventional CPU, many-core CPU, and GPU. We specifically target cloud-resolving resolutions of 3 km and 1 km. To express on-node parallelism we use the C++ library Kokkos, which allows us to achieve a performance portable code in a largely architecture-independent way. Our C++ implementation is at least as fast as the original Fortran implementation on IBM Power9 and Intel Knights Landing processors, proving that the code refactor did not compromise the efficiency on CPU architectures. On the other hand, when using the GPUs, our implementation is able to achieve 0.97 Simulated Years Per Day, running on the full Summit supercomputer. To the best of our knowledge, this is the most achieved to date by any global atmosphere dynamical core running at such resolutions.},
author = {Bertagna, Luca and Guba, Oksana and Taylor, Mark A and Foucar, James G and Larkin, Jeff and Bradley, Andrew M and Rajamanickam, Sivasankaran and Salinger, Andrew G},
booktitle = {Proc. Int. Conf. High Perform. Comput. Networking, Storage Anal.},
file = {::},
isbn = {9781728199986},
keywords = {atmospheric modeling,high performance computing,multicore processing},
publisher = {IEEE Press},
series = {SC '20},
title = {{A Performance-Portable Nonhydrostatic Atmospheric Dycore for the Energy Exascale Earth System Model Running at Cloud-Resolving Resolutions}},
year = {2020}
}
@article{Golaz2019,
abstract = {This work documents the first version of the U.S. Department of Energy (DOE) new Energy Exascale Earth System Model (E3SMv1). We focus on the standard resolution of the fully coupled physical model designed to address DOE mission-relevant water cycle questions. Its components include atmosphere and land (110-km grid spacing), ocean and sea ice (60 km in the midlatitudes and 30 km at the equator and poles), and river transport (55 km) models. This base configuration will also serve as a foundation for additional configurations exploring higher horizontal resolution as well as augmented capabilities in the form of biogeochemistry and cryosphere configurations. The performance of E3SMv1 is evaluated by means of a standard set of Coupled Model Intercomparison Project Phase 6 (CMIP6) Diagnosis, Evaluation, and Characterization of Klima simulations consisting of a long preindustrial control, historical simulations (ensembles of fully coupled and prescribed SSTs) as well as idealized CO2 forcing simulations. The model performs well overall with biases typical of other CMIP-class models, although the simulated Atlantic Meridional Overturning Circulation is weaker than many CMIP-class models. While the E3SMv1 historical ensemble captures the bulk of the observed warming between preindustrial (1850) and present day, the trajectory of the warming diverges from observations in the second half of the twentieth century with a period of delayed warming followed by an excessive warming trend. Using a two-layer energy balance model, we attribute this divergence to the model's strong aerosol-related effective radiative forcing (ERFari+aci = âˆ’1.65 W/m2) and high equilibrium climate sensitivity (ECS = 5.3 K).},
author = {Golaz, Jean Christophe and Caldwell, Peter M. and {Van Roekel}, Luke P. and Petersen, Mark R. and Tang, Qi and Wolfe, Jonathan D. and Abeshu, Guta and Anantharaj, Valentine and Asay-Davis, Xylar S. and Bader, David C. and Baldwin, Sterling A. and Bisht, Gautam and Bogenschutz, Peter A. and Branstetter, Marcia and Brunke, Michael A. and Brus, Steven R. and Burrows, Susannah M. and Cameron-Smith, Philip J. and Donahue, Aaron S. and Deakin, Michael and Easter, Richard C. and Evans, Katherine J. and Feng, Yan and Flanner, Mark and Foucar, James G. and Fyke, Jeremy G. and Griffin, Brian M. and Hannay, C{\'{e}}cile and Harrop, Bryce E. and Hoffman, Mattthew J. and Hunke, Elizabeth C. and Jacob, Robert L. and Jacobsen, Douglas W. and Jeffery, Nicole and Jones, Philip W. and Keen, Noel D. and Klein, Stephen A. and Larson, Vincent E. and Leung, L. Ruby and Li, Hong Yi and Lin, Wuyin and Lipscomb, William H. and Ma, Po Lun and Mahajan, Salil and Maltrud, Mathew E. and Mametjanov, Azamat and McClean, Julie L. and McCoy, Renata B. and Neale, Richard B. and Price, Stephen F. and Qian, Yun and Rasch, Philip J. and {Reeves Eyre}, J. E.Jack and Riley, William J. and Ringler, Todd D. and Roberts, Andrew F. and Roesler, Erika L. and Salinger, Andrew G. and Shaheen, Zeshawn and Shi, Xiaoying and Singh, Balwinder and Tang, Jinyun and Taylor, Mark A. and Thornton, Peter E. and Turner, Adrian K. and Veneziani, Milena and Wan, Hui and Wang, Hailong and Wang, Shanlin and Williams, Dean N. and Wolfram, Phillip J. and Worley, Patrick H. and Xie, Shaocheng and Yang, Yang and Yoon, Jin Ho and Zelinka, Mark D. and Zender, Charles S. and Zeng, Xubin and Zhang, Chengzhu and Zhang, Kai and Zhang, Yuying and Zheng, Xue and Zhou, Tian and Zhu, Qing},
doi = {10.1029/2018MS001603},
file = {::},
issn = {19422466},
journal = {J. Adv. Model. Earth Syst.},
number = {7},
pages = {2089--2129},
publisher = {Blackwell Publishing Ltd},
title = {{The DOE E3SM Coupled Model Version 1: Overview and Evaluation at Standard Resolution}},
volume = {11},
year = {2019}
}
@inproceedings{Ma2020,
abstract = {Performing Deep Neural Network (DNN) computation on hardware accelerators efficiently is challenging. Existing DNN frameworks and compilers often treat the DNN operators in a data flow graph (DFG) as opaque library functions and schedule them onto accelerators to be executed individually. They rely on another layer of scheduler, often implemented in hardware, to exploit the parallelism available in the operators. Such a two-layered approach incurs significant scheduling overhead and often cannot fully utilize the available hardware resources. In this paper, we propose RAM-MER, a DNN compiler design that optimizes the execution of DNN workloads on massively parallel accelerators. RAM-MER generates an efficient static spatio-temporal schedule for a DNN at compile time to minimize scheduling overhead. It maximizes hardware utilization by holistically exploiting parallelism through inter-and intra-operator co-scheduling. RAMMER achieves this by proposing several novel, hardware neutral, and clean abstractions for the computation tasks and the hardware accelerators. These abstractions expose a much richer scheduling space to RAMMER, which employs several heuristics to explore this space and finds efficient schedules. We implement RAMMER for multiple hardware backends such as NVIDIA GPUs, AMD GPUs, and Graphcore IPU. Experiments show RAMMER significantly outperforms state-of-the-art compilers such as TensorFlow XLA and TVM by up to 20.1Ã—. It also outperforms TensorRT, a vendor optimized proprietary DNN inference library from NVIDIA, by up to 3.1Ã—.},
author = {Ma, Lingxiao and Xue, Jilong and Miao, Youshan and Cui, Wei and Hu, Wenxiang and Yang, Fan and Zhang, Lintao and Zhou, Lidong and Xie, Zhiqiang and Yang, Zhi},
file = {:C$\backslash$:/Users/huang/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ma et al. - 2020 - RAMMER Enabling Holistic Deep Learning Compiler Optimizations with rTasks.pdf:pdf},
isbn = {9781939133199},
title = {{RAMMER: Enabling Holistic Deep Learning Compiler Optimizations with rTasks}},
url = {https://www.usenix.org/conference/osdi20/presentation/ma},
year = {2020}
}
@article{Jain2018,
abstract = {Serving deep neural networks in latency critical interactive settings often requires GPU acceleration. However, the small batch sizes typical in online inference results in poor GPU utilization, a potential performance gap which GPU resource sharing can address. In this paper, we explore several techniques to leverage both temporal and spatial multiplexing to improve GPU utilization for deep learning inference workloads. We evaluate the performance trade-offs of each approach with respect to resource-efficiency, latency predictability, and isolation when compared with conventional batched inference. Our experimental analysis suggests up to a 5x potential for improved utilization through the exploration of more advanced spatial and temporal multiplexing strategies. Our preliminary prototype of a dynamic space-time scheduler demonstrates a 3.23x floating-point throughput increase over space-only multiplexing and a 7.73x increase over time-only multiplexing for convolutions, while also providing better isolation and latency predictability.},
archivePrefix = {arXiv},
arxivId = {1901.00041},
author = {Jain, Paras and Mo, Xiangxi and Jain, Ajay and Subbaraj, Harikaran and Durrani, Rehan Sohail and Tumanov, Alexey and Gonzalez, Joseph and Stoica, Ion},
eprint = {1901.00041},
file = {::},
month = {dec},
title = {{Dynamic Space-Time Scheduling for GPU Inference}},
url = {http://arxiv.org/abs/1901.00041},
year = {2018}
}
@inproceedings{Bauer2019,
abstract = {NumPy is a popular Python library used for performing array-based numerical computations. The canonical implementation of NumPy used by most programmers runs on a single CPU core and is parallelized to use multiple cores for some operations. This restriction to a single-node CPU-only execution limits both the size of data that can be handled and the potential speed of NumPy code. In this work we introduce Legate, a drop-in replacement for NumPy that requires only a single-line code change and can scale up to an arbitrary number of GPU accelerated nodes. Legate works by translating NumPy programs to the Legion programming model and then leverages the scalability of the Legion runtime system to distribute data and computations across an arbitrary sized machine. Compared to similar programs written in the distributed Dask array library in Python, Legate achieves speed-ups of up to 10X on 1280 CPUs and 100X on 256 GPUs.},
author = {Bauer, Michael and Garland, Michael},
booktitle = {Int. Conf. High Perform. Comput. Networking, Storage Anal. SC},
doi = {10.1145/3295500.3356175},
file = {::},
isbn = {9781450362290},
issn = {21674337},
keywords = {Control replication,Distributed execution,GPU,HPC,Legate,Legion,Logical regions,NumPy,Python,Task-based runtimes},
month = {nov},
publisher = {IEEE Computer Society},
title = {{Legate NumPy: Accelerated and distributed array computing}},
year = {2019}
}
@article{J2010,
abstract = {As we enter the era of GPU computing, demanding applications with substantial parallelism increasingly use the massively parallel computing capabilities of GPUs to achieve superior performance and efficiency. Today GPU computing enables applications that we previously thought infeasible because of long execution times. With the GPU's rapid evolution from a configurable graphics processor to a pro-grammable parallel processor, the ubiquitous GPU in every PC, laptop, desktop, and workstation is a many-core multi-threaded multiprocessor that excels at both graphics and computing applications. Today's GPUs use hundreds of parallel processor cores executing tens of thousands of parallel threads to rapidly solve large problems having substantial inherent parallelism. They're now the most pervasive massively parallel processing platform ever available, as well as the most cost-effective. Using NVIDIA GPUs as examples, this article describes the evolution of GPU computing and its parallel computing model, the enabling architecture and software developments , how computing applications use CPUÃ¾GPU coprocessing, example application performance speedups, and trends in GPU computing. GPU computing's evolution Why have GPUs evolved to have large numbers of parallel threads and many cores? The driving force continues to be the real-time graphics performance needed to render complex, high-resolution 3D scenes at interactive frame rates for games. Rendering high-definition graphics scenes is a problem with tremendous inherent par-allelism. A graphics programmer writes a single-thread program that draws one pixel, and the GPU runs multiple instances of this thread in parallel-drawing multiple pixels in parallel. Graphics programs, written in shading languages such as Cg or High-Level Shading Language (HLSL), thus scale transparently over a wide range of thread and processor parallelism. Also, GPU computing programs-written in C or CÃ¾Ã¾ with the CUDA parallel computing model, 1,2 or using a parallel computing API inspired by CUDA such as Direct-Compute 3 or OpenCL 4-scale transparently over a wide range of parallelism. Software scalability, too, has enabled GPUs to rapidly increase their parallelism and performance with increasing transistor density.},
author = {J, Nickolls and J, Dally W.},
file = {::},
journal = {IEEE Micro},
pages = {56},
title = {{The GPU Computing Era}},
volume = {30},
year = {2010}
}
@inproceedings{Yashiro2016,
abstract = {We summarize the optimization and performance evalua- Tion of the Nonhydrostatic ICosahedral Atmospheric Model (NICAM) on two different types of supercomputers: The K computer and TSUBAME2.5. First, we evaluated and im- proved several kernels extracted from the model code on the K computer. We did not significantly change the loop and data ordering for sufficient usage of the features of the K computer, such as the hardware-aided thread barrier mechanism and the relatively high bandwidth of the memory, i.e., a 0.5 Byte/FLOP ratio. Loop optimizations and code cleaning for a reduction in memory transfer contributed to a speed-up of the model execution time. The sustained performance ratio of the main loop of the NICAM reached 0.87 PFLOPS with 81,920 nodes on the K computer. For GPU- based calculations, we applied OpenACC to the dynamical core of NICAM. The performance and scalability were evaluated using the TSUBAME2.5 supercomputer. We achieved good performance results, which showed efficient use of the memory throughput performance of the GPU as well as good weak scalability. A dry dynamical core experiment was carried out using 2560 GPUS, which achieved 60 TFLOPS of sustained performance.},
author = {Yashiro, Hisashi and Terai, Masaaki and Yoshida, Ryuji and Iga, Shin Ichi and Minami, Kazuo and Tomita, Hirofumi},
booktitle = {PASC 2016 - Proc. Platf. Adv. Sci. Comput. Conf.},
doi = {10.1145/2929908.2929911},
file = {::},
isbn = {9781450341264},
keywords = {Climate,Extreme-scale computing,GCM,K computer,Memory-bound,OpenACC,TSUBAME2.5,Weather},
month = {jun},
publisher = {Association for Computing Machinery, Inc},
title = {{Performance analysis and optimization of nonhydrostatic icosahedral atmospheric model (NICAM) on the K computer and TSUBAME2.5}},
year = {2016}
}
@inproceedings{Slaughter2019,
abstract = {Dynamic languages provide the flexibility needed to implement expressive support for task-based parallel program-ming constructs. We present Pygion, a Python interface for the Legion task-based programming system, and show that it can provide features comparable to Regent, a statically typed programming language with dedicated support for the Legion programming model. Furthermore, we show that the dynamic nature of Python permits the implementation of several key optimizations (index launches, futures, mapping) currently imple-mented in the Regent compiler. Together these features enable Pygion code that is comparable in expressiveness but more flexible than Regent, and substantially more concise, less error prone, and easier to use than C++ Legion code. Pygion is designed to interoperate with Regent and can use Regent to generate high-performance CPU and GPU kernel implementations. We show that, in combination with high-performance kernels written in Regent, Pygion is able to achieve efficient, scalable execution on up to 512 nodes of the heterogeneous supercomputer Piz Daint.},
author = {Slaughter, Elliott and Aiken, Alex},
booktitle = {Proc. PAW-ATM 2019 Parallel Appl. Work. Altern. to MPI+X, Held conjunction with SC 2019 Int. Conf. High Perform. Comput. Networking, Storage Anal.},
doi = {10.1109/PAW-ATM49560.2019.00011},
file = {::},
isbn = {9781728159799},
keywords = {Legion,Pygion,Python,task-based parallelism},
pages = {58--72},
title = {{Pygion: Flexible, Scalable Task-Based Parallelism with Python}},
year = {2019}
}
@article{Ding2020,
abstract = {To accelerate CNN inference, existing deep learning frameworks focus on optimizing intra-operator parallelization. However, a single operator can no longer fully utilize the available parallelism given the rapid advances in high-performance hardware, resulting in a large gap between the peak performance and the real performance. This performance gap is more severe under smaller batch sizes. In this work, we extensively study the parallelism between operators and propose Inter-Operator Scheduler (IOS) to automatically schedule the execution of multiple operators in parallel. IOS utilizes dynamic programming to find a scheduling policy specialized for the target hardware. IOS consistently outperforms state-of-the-art libraries (e.g., TensorRT) by 1.1 to 1.5x on modern CNN benchmarks.},
archivePrefix = {arXiv},
arxivId = {2011.01302},
author = {Ding, Yaoyao and Zhu, Ligeng and Jia, Zhihao and Pekhimenko, Gennady and Han, Song},
eprint = {2011.01302},
file = {::},
month = {nov},
title = {{IOS: Inter-Operator Scheduler for CNN Acceleration}},
url = {http://arxiv.org/abs/2011.01302},
year = {2020}
}
@inproceedings{Yang2016,
abstract = {An ultra-scalable fully-implicit solver is developed for stiff time-dependent problems arising from the hyperbolic conservation laws in nonhydrostatic atmospheric dynamics. In the solver, we propose a highly efficient hybrid domain-decomposed multigrid preconditioner that can greatly accelerate the convergence rate at the extreme scale. For solving the overlapped subdomain problems, a geometry-based pipelined incomplete LU factorization method is designed to further exploit the on-chip fine-grained concurrency. We perform systematic optimizations on different hardware levels to achieve best utilization of the heterogeneous computing units and substantial reduction of data movement cost. The fully-implicit solver successfully scales to the entire system of the Sunway TaihuLight supercomputer with over 10.5M heterogeneous cores, sustaining an aggregate performance of 7.95 PFLOPS in double-precision, and enables fast and accurate atmospheric simulations at the 488-m horizontal resolution (over 770 billion unknowns) with 0.07 simulated-years-per-day. This is, to our knowledge, the largest fully-implicit simulation to date.},
author = {Yang, Chao and Xue, Wei and Fu, Haohuan and You, Hongtao and Wang, Xinliang and Ao, Yulong and Liu, Fangfang and Gan, Lin and Xu, Ping and Wang, Lanning and Yang, Guangwen and Zheng, Weimin},
booktitle = {Int. Conf. High Perform. Comput. Networking, Storage Anal. SC},
doi = {10.1109/SC.2016.5},
isbn = {9781467388153},
issn = {21674337},
keywords = {Sunway TaihuLight supercomputer,atmospheric modeling,fully implicit solver,heterogeneous many-core architecture},
title = {{10M-Core Scalable Fully-Implicit Solver for Nonhydrostatic Atmospheric Dynamics}},
year = {2016}
}
@article{Fuhrer2018,
abstract = {The best hope for reducing long-standing global climate model biases is by increasing resolution to the kilometer scale. Here we present results from an ultrahigh-resolution non-hydrostatic climate model for a near-global setup running on the full Piz Daint supercomputer on 4888 GPUs (graphics processing units). The dynamical core of the model has been completely rewritten using a domain-specific language (DSL) for performance portability across different hardware architectures. Physical parameterizations and diagnostics have been ported using compiler directives. To our knowledge this represents the first complete atmospheric model being run entirely on accelerators on this scale. At a grid spacing of 930 m (1.9 km), we achieve a simulation throughput of 0.043 (0.23) simulated years per day and an energy consumption of 596 MWh per simulated year. Furthermore , we propose a new memory usage efficiency (MUE) metric that considers how efficiently the memory bandwidth-the dominant bottleneck of climate codes-is being used.},
author = {Fuhrer, Oliver and Chadha, Tarun and Hoefler, Torsten and Kwasniewski, Grzegorz and Lapillonne, Xavier and Leutwyler, David and L{\"{u}}thi, Daniel and Osuna, Carlos and Sch{\"{a}}r, Christoph and Schulthess, Thomas C and Vogt, Hannes},
doi = {10.3929/ethz-b-000265137},
file = {:C$\backslash$:/Users/huang/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fuhrer et al. - 2018 - Near-global climate simulation at 1 km resolution establishing a performance baseline on 4888 GPUs with COSMO 5.0.pdf:pdf},
journal = {ETH Libr. Geosci. Model Dev},
pages = {1665--1681},
title = {{Near-global climate simulation at 1 km resolution: establishing a performance baseline on 4888 GPUs with COSMO 5.0}},
url = {http://doi.org/10.5194/gmd-11-1665-2018},
volume = {11},
year = {2018}
}
@inproceedings{Bauer2012,
abstract = {Modern parallel architectures have both heterogeneous processors and deep, complex memory hierarchies. We present Legion, a programming model and runtime system for achieving high performance on these machines. Legion is organized around logical regions, which express both locality and independence of program data, and tasks, functions that perform computations on regions. We describe a runtime system that dynamically extracts parallelism from Legion programs, using a distributed, parallel scheduling algorithm that identifies both independent tasks and nested parallelism. Legion also enables explicit, programmer controlled movement of data through the memory hierarchy and placement of tasks based on locality information via a novel mapping interface. We evaluate our Legion implementation on three applications: fluid-flow on a regular grid, a three-level AMR code solving a heat diffusion equation, and a circuit simulation. {\textcopyright} 2012 IEEE.},
author = {Bauer, Michael and Treichler, Sean and Slaughter, Elliott and Aiken, Alex},
booktitle = {Int. Conf. High Perform. Comput. Networking, Storage Anal. SC},
doi = {10.1109/SC.2012.71},
file = {::},
isbn = {9781467308069},
issn = {21674329},
publisher = {IEEE Computer Society},
title = {{Legion: Expressing locality and independence with logical regions}},
year = {2012}
}
